---
layout: post
title: blog review 第二十二期
categories: [review]
tags: [rocksdb,pg,hive,mapreduce,rockset]
---
最近感悟

有些事情自己不接触到是不会相信的，比如系统API不稳定，尤其是write read。有一些歌开源代码我就不说是谁了，系统接口永远默认成功我操

关键是定位问题的盲点也在这里，永远不会去考虑系统的错误，而是查业务自身有没有问题。导致白白浪费时间。在不靠谱的代码上堆叠出来的业务，又咋可能靠谱

<!-- more -->

## rocksdb最后一层的compact问题

最近和sue讨论rockdb值得记录一下:

如果周期性的反复删除重写一组key，这组key最终会落在最后一层，而最后一层的compact调度是比较晚的，最后一层也不参加score计算compact，所以需要主动触发compact来把这种key删除掉

这也是为什么myrocks会有针对delete的计数配置的原因

```
     rocksdb_compaction_sequential_deletes   0
     rocksdb_compaction_sequential_deletes_count_sd  O
     rocksdb_compaction_sequential_deletes_file_size 0
     rocksdb_compaction_sequential_deletes_window    0
```

类似Pika也有一个计数 https://github.com/OpenAtomFoundation/pika/blob/2f71d18ad81fa01e3239e5f8d70dea5b3694ff3d/src/storage/src/redis_hashes.cc#L272

```cpp
  s = db_->Write(default_write_options_, &batch);
  UpdateSpecificKeyStatistics(key.ToString(), statistic);
  return s;
```
原子的。性能太差，我之前改过一个版本直接删了。还是有可取之处的，不过用atomic太扯里。应该thread_local counter


rocksdb的代码，搜

```c++
kBottommostFiles
LevelCompactionBuilder::SetupInitialFiles()
```

就能看到了

## [Erasure Coding versus Tail Latency](https://brooker.co.za/blog/2023/01/06/erasure.html)

backup request是发两次选最快的一次么，总之这种可以降低延迟

发两次，选一次，发M次，选N(`N<M`)次，我操，纠删码的原理，感觉是这种发两次的拓展情况

所以就存在一种用法，一个对象分K个，r个冗余，从K+r里读k个就行了

我操，EC-Cache！重大发现！不好意思，有人想到了https://zhuanlan.zhihu.com/p/24713081 他妈的

当然这种玩法肯定是能降低延迟的，就是得改造

## [Postgres: The Graph Database You Didn&#39;t Know You Had](https://www.dylanpaulus.com/posts/postgres-is-a-graph-database)

```sql
CREATE TABLE nodes (
  id SERIAL PRIMARY KEY,
  data VARCHAR(255)
);
CREATE TABLE edges (
  previous_node INTEGER REFERENCES nodes(id),
  next_node INTEGER REFERENCES nodes(id),
  PRIMARY KEY (previous_node, next_node)
);
```

第一张表是节点，第二张表是第一张表的id和关联

查询依赖

```sql
SELECT id, data
FROM nodes
JOIN edges ON nodes.id = edges.next_node
WHERE edges.previous_node = 1;
```

查id为1 的相邻节点

如果复杂点，查id为1 点相邻节点的相邻节点呢？递归了

用PG特殊功能 WITH RECURSIVE

```sql
WITH RECURSIVE friend_of_friend AS (
  SELECT edges.next_node
  FROM edges
  WHERE edges.previous_node = 1
  UNION
  SELECT edges.next_node
  FROM edges
  JOIN friend_of_friend ON edges.previous_node = friend_of_friend.next_node
)
SELECT nodes.data
FROM nodes
JOIN friend_of_friend ON nodes.id = friend_of_friend.next_node;
```

WITH RECURSIVE语法

```sql
WITH RECURSIVE {name} AS (
  {base case}
  UNION
  {recursive case}
)
```

## [Hive数据导出的几种方式](https://www.cnblogs.com/sheng-sjk/p/13940642.html)

我以为select *会很快，但是不如直接导出HDFS文件。离谱

```sql

# 1
insert overwrite directory '/home/data/' select * from hive_table;

# 2
insert overwrite local directory '/home/data/' select * from hive_table

row format delimited fields terminated by ‘\t’  #字段间用\t分割

stored as textfile;   #导出文件的存储格式为textfile
```

```shell
export table hive_table to '/home/data/';
```

这和上面一样


## [一种基于DAG的MapReduce调度算法](https://www.jsjkx.com/CN/article/openArticlePDF.jsp?id=1319)

节点主动申请任务代替调度器自身调度。

如何根据DAG排序？说了个向上排序，但是评估数据怎么算的？都没说

## 数据本地性感知的 MapReduce负载均衡策略

基于hash分片，一般来说，数据不会不均匀，如果遇到数据倾斜怎么办，这里就是提前采样，判定每个分片数据规模，然后调度的时候拆分一下。

采样一般来说都有，但是基本都是装装样子，没用上


## [Introducing Compute-Compute Separation for Real-Time Analytics](https://rockset.com/blog/introducing-compute-compute-separation/)

<img src="https://images.ctfassets.net/1d31s1aajogl/5PK8lzle4qDpts9MJGv6tV/3a925841f48c4c330c619e8b1002561e/Screen_Shot_2023-02-28_at_5.48.37_PM.png?w=1676&fm=webp" width="80%">

数据导入到ingest节点，ingest生成数据，然后ingest节点复制同步到线上query节点

回顾一下离线导入逻辑，一般都是有个mapreduce系统spark之类，生成线上的数据，sst文件，上传到对象存储，然后db端从对象存储里下载，ingest导入

rockset本身是集成对象存储的，那还拐弯干啥？直接写到对象存储，然后复制一份到SSD，上线，这也就是ingest节点的作用，query节点直接共享SSD，切一个snapshot的功夫

本质上是把MapReduce直接生成的这个步骤放到线上集群的节点来处理了

离线导入的场景，不能满足流式的场景，这种设计，流式的导入也是没问题的

另外，能省掉中间产物上传下载的时间/开销

这种设计query节点也能无限扩

这里有详细的讨论 https://rockset.com/blog/tech-overview-compute-compute-separation/

<img src="https://images.ctfassets.net/1d31s1aajogl/C2k50nHY0BCwi8r8Rdr7E/29f61b941011ef9b9b81c9e588e1ad77/Screen_Shot_2023-04-11_at_5.34.00_PM.png?w=1671&fm=webp" width="80%">

这个图更明确一些


## [Offline Is Just Online With Extreme Latency](https://blog.jim-nielsen.com/2023/offline-is-online-with-extreme-latency/)

幽默

<img src="https://cdn.jim-nielsen.com/blog/2023/offline-is-extreme-latency.png" width="80%">


## [So, You Want To Build A DBaaS](https://matt.blwt.io/post/so-you-want-to-build-a-dbaas/)

优势在哪里？稳定性？能解决什么问题？上限在哪里？能不能可量化可预测性能？单机能力怎么样？做到最优了么？能覆盖大部分应用场景么？你的最大优势在哪里？

述职呢搁着

## Hekaton: SQL Server's Memory-Optimized OLTP Engine


```txt

索引管理

所有支持MVCC的DBMSs都将版本数据和索引数据分开存储。我们可以将索引看作KV键值对，键是被索引的数据行中的字段值（例如ID），值是索引对应的数据行的指针。

主键索引的情况比较简单，因为主键（同时也是索引的Key）是保持不变的，索引的Value总是指向版本数据链的起点，比如在InnoDB中，主键索引的数据行就是指向主表的。在主键索引中，索引的键值对指针会发生什么样的变更，取决于DBMS使用了哪种的数据存储方式。

对于Delta存储，我们上面讨论过，主表永远都是存的master版本数据，它是原地更新的，因此在更新数据时，主表中的数据行位置不发生改变，因此索引Value的指针也没有发生改变。

对于Append-only的存储，版本数据链有两种不同的方向：

    O2N，新的版本数据Append在版本链的末端，因此索引的Value指针始终指向链表的起点不变；只有在发生GC的时候才会调整指针地址
    N2O，每当产生新版本时，都需要调整索引值的指针，此时DBMS一般会在索引上进行DELETE & INSERT的操作完成调整

对于辅助索引，被索引的字段值（同时也是索引中的Key）可能改变，索引的Value指向的版本数据也有可能改变。因此有不同的方案对索引中的指针进行管理。
Logical Pointers

最常用的方案是建立一层中间表，让索引的Value能够一直不变，例如指向主键。这种方案也是InnoDB在使用的，所以我们通常说辅助索引会包含被索引值以及主键值。通过主键值将索引中的指针固定下来，这样每当版本数据链表起点发生改变时，只需要同时更新主键值对应的指针。虽然只有一个辅助索引时，听起来改动的复杂度是相同的，都是改变了1处指针，但是当有许多辅助索引时，就会是O(1) vs. O(n)的差异了。

借助主键的坏处是辅助索引的体积会随着主键体积发生变化，另一个方案是为逻辑tuple提供64-bit的唯一ID。实际上思路并没有区别，都是在物理版本链和索引之间增加了一层映射，只是看映射的内容如何选取一个唯一固定、节约空间的值。
Physical Pointers

Uber曾经发过一篇文章：《Why Uber Engineering Switched from Postgres to MySQL》，实际上他们并不是一开始就在用Postgres。Uber最早使用的也是MySQL，中途招了一些热衷于Postgres的工程师，所以他们就从MySQL切到了Postgres。他们在表中加了非常多的辅助索引，在使用过程中发现，Postgres的辅助索引是指向磁盘中的版本链起点的，在版本链起点发生变动时，多个辅助索引的指针就要发生修改。在Append-only的存储方式下，这种设计的好处是没有通过中间层映射（例如主键ID）回表查询，坏处也非常明显，当辅助索引非常多的时候，版本数据链起点的变更将会导致所有辅助索引的指针都需要更新。

目前还有一些DBMS使用了这种方案，例如MemSQL、Hekaton。如果Uber的工程师有读过这篇论文，他们可能可以节约不少的迁移成本。

```

另外[The Part of PostgreSQL We Hate the Most](https://ottertune.com/blog/the-part-of-postgresql-we-hate-the-most/)

> Most DBMSs, including Oracle and MySQL, implement N2O. But PostgreSQL stands alone in using O2N 
> (except for Microsoft’s In-Memory OLTP engine for SQL Server).

数据膨胀问题，不及时compact搜索性能差，另外对于这种场景，也有优化，索引分裂？总之空间换时间


## TODO
https://github.com/madsim-rs/madsim

https://sled.rs/simulation.html

https://apple.github.io/foundationdb/testing.html


https://github.com/zhuichao001/hawker

https://github.com/zhuichao001/rocksdb-tuning

http://c.biancheng.net/view/3453.html

https://www.youtube.com/watch?v=bZOvAKGkzpQ&ab_channel=CMUDatabaseGroup

https://kuzudb.com/blog/wcoj.html

https://www.youtube.com/watch?v=vIRjSdTCIEU&ab_channel=PerformanceSummit

https://www.evanjones.ca/hugepages-are-a-good-idea.html

https://sqlfordevs.com/tips#Schema

https://samwho.dev/load-balancing/#playground


https://lewissbaker.github.io/2022/08/27/understanding-the-compiler-transform

https://yasongxu.gitbook.io/container-monitor/yi-.-kai-yuan-fang-an/di-1-zhang-cai-ji/node-exporter

https://dotat.at/@/2023-02-28-qp-bind.html

https://dotat.at/@/2022-11-17-dns-decompress.html

https://dotat.at/@/2022-06-27-tolower-swar.html

https://gitlab.isc.org/isc-projects/bind9/-/blob/main/doc/design/qp-trie.md

https://gitlab.isc.org/isc-projects/bind9/-/blob/main/doc/dev/qsbr.md


https://muratbuffalo.blogspot.com/2023/02/polyjuice-high-performance-transactions.html

http://muratbuffalo.blogspot.com/2023/02/speedy-transactions-in-multicore-in.html


http://muratbuffalo.blogspot.com/2023/03/aria-fast-and-practical-deterministic.html

https://thebuild.com//presentations/logical-nordic-pgday-2023.pdf