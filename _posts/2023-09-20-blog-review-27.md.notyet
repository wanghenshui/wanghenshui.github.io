---
layout: post
title: blog review 第二十七期
categories: [review]
tags: [cache]
---

面向离职编程，把你每一行代码，每个文档，都当做离职交接文档。配置文件的详细描述，代码的打包，部署，

测试环境和正式环境的配置，TODO，如何扩展，如何让下一个接手你代码的人看你的代码的时候被你的代码惊艳到哭。

https://www.zhihu.com/question/68611994/answer/298467553



<!-- more -->

和sue又讨论了一个场景，他有个导入服务和tendis，导入期间延迟升高

导入服务上传文件影响tendis网络延迟了，换成rsync就缓解了

挺离谱的

ingest导致的升高，可能是memtable重叠导致的写停/compaction


## [SQL join flavors](https://antonz.org/sql-join/)



一张图解释join，挺好的，马上就懂了

<img src="https://antonz.org/sql-join/joins.png" alt="" width="60%"> 



## [FIFO queues are all you need for cache eviction](https://blog.jasony.me/system/cache/2023/08/01/s3fifo)


感觉就是2Q的一种变种 代码在这 https://github.com/Thesys-lab/sosp23-s3fifo/blob/main/libCacheSim/libCacheSim/cache/eviction/S3FIFO.c





## [Omid Transaction Processing](https://zhuanlan.zhihu.com/p/34764376)

TODO

## [Integrate YugabyteDB Logs into Splunk for Comprehensive Monitoring and Analysis](https://www.yugabyte.com/blog/get-data-in-splunk/)

TODO


## [Data Replication in YugabyteDB](https://www.yugabyte.com/blog/data-replication/)

TODO


## 连接数超过连接池之后的行为是什么样的？临时连接？

请求限流，没有连接就等，间隔MS之后再创建新的连接，把连接创建平稳下来

问题：大量的连接等同于泄漏，即使平稳了曲线

## 全链路校验

## 降冷

从Raft log层回写key→ cos文件位置的时候，一定要把降冷的kv的version带回来执行cas操作，只有当最新kv仍然是这个version时才能回写，不然可能会覆盖用户最新的写入


## 热点冲突

- shared promise 合并
- writecache 增加流程提前解锁，定期刷writecache - 延迟升高


| SAMSUNG MZQL23T8HCLS-00B7C | 210 | 3.84 TB | 6900 MB/s     | 4100 MB/s     | 1   | [https://semiconductor.samsung.com/ssd/datacenter-ssd/pm9a3/mzql23t8hcjs-00a07/](https://semiconductor.samsung.com/ssd/datacenter-ssd/pm9a3/mzql23t8hcjs-00a07/ "https://semiconductor.samsung.com/ssd/datacenter-ssd/pm9a3/mzql23t8hcjs-00a07/")                                                                                                                                                          |
| ---------------------------- | ----- | --------- | --------------- | --------------- | ----- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| INTEL SSDPF2KX038TZ        | 508 | 3.84 TB | 6500 MBps     | 3400 MBps     | 1   | [https://www.wiredzone.com/shop/product/10021441-intel-ssdpf2kx038tz-3-84tb-drive-nvme-pcie-4-0-u-2-15mm-1dwpd-8252](https://www.wiredzone.com/shop/product/10021441-intel-ssdpf2kx038tz-3-84tb-drive-nvme-pcie-4-0-u-2-15mm-1dwpd-8252 "https://www.wiredzone.com/shop/product/10021441-intel-ssdpf2kx038tz-3-84tb-drive-nvme-pcie-4-0-u-2-15mm-1dwpd-8252")                                              |
| SAMSUNG MZWLJ3T8HBLS-0007C | 44  | 3.84 TB | 7000 MB/s     | 3800 MB/s     | 1   | [https://semiconductor.samsung.com/ssd/enterprise-ssd/pm1733-pm1735/mzwlj3t8hbls-00007/](https://semiconductor.samsung.com/ssd/enterprise-ssd/pm1733-pm1735/mzwlj3t8hbls-00007/ "https://semiconductor.samsung.com/ssd/enterprise-ssd/pm1733-pm1735/mzwlj3t8hbls-00007/")                                                                                                                                  |
| INTEL SSDPE2KX040T8        | 63  | 3.84 TB | 2.93 GB/s     | 2.83 GB/s     | 1   | [https://www.wiredzone.com/shop/product/10028040-intel-ssdpe2kx040t8-hard-drive-4tb-nvme-pcie-3-1-3d-tlc-2-5in-u-2-15mm-1dwpd-2266](https://www.wiredzone.com/shop/product/10028040-intel-ssdpe2kx040t8-hard-drive-4tb-nvme-pcie-3-1-3d-tlc-2-5in-u-2-15mm-1dwpd-2266 "https://www.wiredzone.com/shop/product/10028040-intel-ssdpe2kx040t8-hard-drive-4tb-nvme-pcie-3-1-3d-tlc-2-5in-u-2-15mm-1dwpd-2266") |
| HFS3T8GETFEI-D430A         | 99  | 3.84 TB | **6500 MB/s** | **3700 MB/s** | 1   | [https://product.skhynix.com/products/ssd/essd.go](https://product.skhynix.com/products/ssd/essd.go "https://product.skhynix.com/products/ssd/essd.go")                                                                                                                                                                                                                                                    |



| **设备**  | **进程** | **流程**  | 
| ----------------- | ---------------- | ----------------- |
| 客户端          | client         | 发起sync        |
|                 | 内核           | 物理网卡        |
| 服务端gw物理机  | 内核           | 物理网卡 bond1  |
|                 |                | iptables        |
|                 |                | ipvs            |
|                 |                | 虚拟网卡 vxnet  |
|                 | flannel        | 转发，udp?      |
|                 | gateway        | listen & accept |
|                 |                | 协议解析        |
|                 |                | 路由查询        |
|                 |                | 子任务拆分执行  |
|                 |                | backup request  |
|                 |                | redirect        |
|                 | 内核           | 虚拟网卡 vxnet  |
| 服务端dbs物理机 | 内核           | 虚拟网卡 vxnet  |
|                 | flannel        | 本地转发        |
|                 | database       | listen & accept |


服务进程(gw/dbs等)连接处理异常

场景：

    业务请求大量超时，或存在明显的IP到IP的延时高或超时

表现：

    服务端recv-q阻塞，数值长时间未变动或增加

可能的原因：

    过载，超过处理速率

        检查cpu是否占满

            检查单核

            检查单线程

            检查k8s 的cpu是否达到limit

            检查numa

        检查是否存在pipeline串行

    软件bug，连接未处理

解决手段：

    过载则扩容，注意避免hash映射导致的集中

    bug要修，紧急手段要具体分析

k8s组件导致异常连接

场景：

    少量IP到IP之前，访问完全不通

    服务端是k8s的非host网络

表现：

    服务端连未绑定进程(线程id显示 - )，状态是ESTABLISHED，截图不准确(没找到其他图)

      

    对应端口是kube-proxy或者galaxy在监听

原因：

    galaxy/kubeproxy进程listen后，相关服务的pod重启过程中客户端尝试建立连接，将不会触发accept

处理手段：

    有访问的情况下，可以通过tcpkill断掉指定连接，影响范围较小

    无论有无访问，均可通过重启galaxy/kubeproxy(根据对应监听端口确认)的方式来进行恢复

自动断链抖动
dcc断链

dcc有默认断链时长，关键字close
trpc断链

trpc client/service均有断链时长

关键词为idle_time
内核断链

内核默认7200s断链(2h)
sysctl net.ipv4.tcp_keepalive_time
ivps断链

ipvs tcp 默认900s断链(15min)

新上集群调整为7200s(2h)
ivpsadm -L --timeout
conntrack断链

默认432000s断链(3day)
sysctl net.netfilter.nf_conntrack_tcp_timeout_established

 
dns/路由异常

todo
dns缺失

nslookup $dns
dns同步缓慢

查看etcd cpu
路由缺失

todo，近期无路由缺失case
路由表过大
iptables -L

上述查询命令查询缓慢，会高频提示有锁
iptables-save | wc -l

检查表项目，通常是表项过多(1W~10W)

此时kubelet组件可能会注册iptables失败，但是仍然ready，导致访问失败

 

可以通过缩减表项、增加kubelet组件sync频率、或者切换到ipvs策略来解决


netstat
netstat -nap | grep gateway | grep ESTAB

其中，-p会打印线程名；会导致开销增加。频繁执行时一般不加-p

注意，容器内外执行效果不同。目前监控只抓了host的
ss
ss -nap | grep gateway | grep ESTAB

效率优于netstat，会打印fd。推荐

据说在老版本linux没有安装。但是目前现网设备都支持
tcpkill

伪装rst包以停连接，只能用于有请求的连接。若无请求，则联系开发使用特殊版本。对业务来说，能够感知连接关闭，可能会有微量失败

    安装，建议在宿主机

    yum install dsniff -y

使用netstat获取需要断链的信息，并聚合

执行，语法和tcpdump近似

        tcpkill -i bond1 dst port 20000 and src host 1.1.1.1

        会持续抓包断链，需要一定时间

        业务可能会新建连接，因此不保证业务访问一定掉底

    重新检查连接是否存在

iptables
# 拉取
iptables -L
# 等待拉取
iptables -L -w
# nat表拉取
iptables -L -w -t nat
# 纯拉取，无锁
iptables-save
ipvsadm
yum install -y ipvsadm
ipvsadm-save

ipset list