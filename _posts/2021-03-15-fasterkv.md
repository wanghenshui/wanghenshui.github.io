---
layout: post
title: fasterkv介绍
categories: [database]
tags: [hashtable, bitcask, todo, fasterkv, epoch, tcc]
---

我感觉就像个bitcask加强版

而且是内存丢失版，不保证罗盘的

<!-- more -->



## fastkv store设计

```c++
 private:
// 推进版本号
  LightEpoch epoch_;

 public:
  disk_t disk;
  hlog_t hlog;

 private:
  static constexpr bool kCopyReadsToTail = false;
  static constexpr uint64_t kGcHashTableChunkSize = 16384;
  static constexpr uint64_t kGrowHashTableChunkSize = 16384;

  bool fold_over_snapshot = true;

  /// Initial size of the table
  uint64_t min_table_size_;

  // Allocator for the hash buckets that don't fit in the hash table.
  // hash撞了的key放这里
  MallocFixedPageSize<HashBucket, disk_t> overflow_buckets_allocator_[2];

  // An array of size two, that contains the old and new versions of the hash-table
  InternalHashTable<disk_t> state_[2];

  CheckpointLocks checkpoint_locks_;

  ResizeInfo resize_info_;

  AtomicSystemState system_state_;

  /// Checkpoint/recovery state.
  CheckpointState<file_t> checkpoint_;
  /// Garbage collection state.
  GcState gc_;
  /// Grow (hash table) state.
  GrowState grow_;

  /// Global count of pending I/Os, used for throttling.
  std::atomic<uint64_t> num_pending_ios;

  /// Space for two contexts per thread, stored inline.
  ThreadContext thread_contexts_[Thread::kMaxNumThreads];
```



## address设计

```c++
class Address {
  ///
    /// An invalid address, used when you need to initialize an address but you don't have a valid
  /// value for it yet. NOTE: set to 1, not 0, to distinguish an invalid hash bucket entry
  /// (initialized to all zeros) from a valid hash bucket entry that points to an invalid address.
  static constexpr uint64_t kInvalidAddress = 1;

  /// A logical address is 8 bytes.
  /// --of which 48 bits are used for the address. (The remaining 16 bits are used by the hash
  /// table, for control bits and the tag.)
  // 64位 48位用来做地址，16预留给hashtable
  // 地址组成 page + page offset，通过page index定位page
  static constexpr uint64_t kAddressBits = 48;
  static constexpr uint64_t kMaxAddress = ((uint64_t)1 << kAddressBits) - 1;
  /// --of which 25 bits are used for offsets into a page, of size 2^25 = 32 MB.
  // page offset预留位
  static constexpr uint64_t kOffsetBits = 25;
  static constexpr uint32_t kMaxOffset = ((uint32_t)1 << kOffsetBits) - 1;
  /// --and the remaining 23 bits are used for the page index, allowing for approximately 8 million
  /// pages.
  // page index预留位
  static constexpr uint64_t kPageBits = kAddressBits - kOffsetBits;
  static constexpr uint32_t kMaxPage = ((uint32_t)1 << kPageBits) - 1;
  ////
  union {
      struct {
        uint64_t offset_ : kOffsetBits;         // 25 bits
        uint64_t page_ : kPageBits;  // 23 bits
        uint64_t reserved_ : 64 - kAddressBits; // 16 bits
      };
      uint64_t control_;
    };
};
```

利用了位域来省空间, 做到cacheline对齐，避免 false sharing

AtomicAddress是Address的原子封装

### FixedPageAddress

类似Address，给MallocFixedPageSize用的

```c++
  /// A fixed-page address is 8 bytes.
  /// --of which 48 bits are used for the address. (The remaining 16 bits are used by the hash
  /// table, for control bits and the tag.)
  static constexpr uint64_t kAddressBits = 48;
  static constexpr uint64_t kMaxAddress = ((uint64_t)1 << kAddressBits) - 1;

  /// --of which 20 bits are used for offsets into a page, of size 2^20 = 1 million items.
  static constexpr uint64_t kOffsetBits = 20;
  static constexpr uint64_t kMaxOffset = ((uint64_t)1 << kOffsetBits) - 1;

  /// --and the remaining 28 bits are used for the page index, allowing for approximately 256
  /// million pages.
  static constexpr uint64_t kPageBits = kAddressBits - kOffsetBits;
  static constexpr uint64_t kMaxPage = ((uint64_t)1 << kPageBits) - 1;

  union {
      struct {
        uint64_t offset_ : kOffsetBits;        // 20 bits
        uint64_t page_ : kPageBits;            // 28 bits
        uint64_t reserved : 64 - kAddressBits; // 16 bits
      };
      uint64_t control_;
    };
```

### keyhash



```c++
/// Hash of a key is 8 bytes, compatible with hash bucket entry.
struct KeyHash {
  KeyHash()
    : control_{ 0 } {
  }
  explicit KeyHash(uint64_t code)
    : control_{ code } {
  }
  KeyHash(const KeyHash& other)
    : control_{ other.control_ } {
  }

  KeyHash& operator=(const KeyHash& other) {
    control_ = other.control_;
    return *this;
  }

  /// Truncate the key hash's address to get the page_index into a hash table of specified size.
  //快速算size的余数，当且仅当size是2的幂才有效
  inline uint64_t idx(uint64_t size) const {
    assert(Utility::IsPowerOfTwo(size));
    return address_ & (size - 1);
  }

  /// The tag (14 bits) serves as a discriminator inside a hash bucket. (Hash buckets use 2 bits
  /// for control and 48 bits for log-structured store offset; the remaining 14 bits discriminate
  /// between different key hashes stored in the same bucket.)
  inline uint16_t tag() const {
    return static_cast<uint16_t>(tag_);
  }

 private:
  union {
      struct {
        uint64_t address_ : 48;
        uint64_t tag_ : 14;
        uint64_t not_used_ : 2;
      };
      uint64_t control_;
    };
};
```

这里 address tag都是key 的hash的一段

idx表示用key的大小来做分段，能分的

hash表如何决定具体的entry？

```c++
  inline HashBucket& bucket(KeyHash hash) {
    return buckets_[hash.idx(size_)];
  }
```

idx根据一段hash算出这段hash的特征值，也就是size的余数到bucket的某个槽，然后tag也是hash的一段，这两个来保证不冲突





## Epoch

### epoch基本概念

全局epoch current_epoch E

线程entry自己的epoch local_current_epoch  ET

safe epoch，所有的epoch都大于的epoch

safe_to_reclaim_epoch Es 表示最大的那个safe epoch，也就是所有epoch中最小的那个 -1 

### EpochAction

Acquire 申请Entry 初始化ET为E

Refresh 更新ET ES 触发ready action

BumpEpoch 推进E 注册新的action

Release 移除Entry



**Q:kMaxNumThreads = 96写死的，这个和什么有关系？**

entry是cacheline对齐的 

epoch初始化

```c++
  void Initialize(uint32_t size) {
    num_entries_ = size;
    // do cache-line alignment
    table_ = reinterpret_cast<Entry*>(aligned_alloc(Constants::kCacheLineBytes,
                                      (size + 2) * sizeof(Entry)));
    new(table_) Entry[size + 2];
    current_epoch = 1;
    safe_to_reclaim_epoch = 0;
    for(uint32_t idx = 0; idx < kDrainListSize; ++idx) {
      drain_list_[idx].Initialize();
    }
    drain_count_ = 0;
  }
  /// List of action, epoch pairs containing actions to performed when an epoch becomes
  /// safe to reclaim.
  EpochAction drain_list_[kDrainListSize];
  /// Count of drain actions
  std::atomic<uint32_t> drain_count_;
```

**Q: 为什么多分配两个？**

访问/刷新，通过protect

```c++
  /// Enter the thread into the protected code region
  /// Process entries in drain list if possible
  inline uint64_t ProtectAndDrain() {
    uint32_t entry = Thread::id();
    table_[entry].local_current_epoch = current_epoch.load();
    if(drain_count_.load() > 0) {
      Drain(table_[entry].local_current_epoch);
    }
    return table_[entry].local_current_epoch;
  }
```

这里的threadid，通过preserveEntry初始化

```c++
  inline static uint32_t ReserveEntry() {
#ifdef COUNT_ACTIVE_THREADS
    int32_t result = ++current_num_threads_;
    assert(result < kMaxNumThreads);
#endif
    uint32_t start = next_index_++;
    uint32_t end = start + 2 * kMaxNumThreads;
    for(uint32_t id = start; id < end; ++id) {
      bool expected = false;
      if(id_used_[id % kMaxNumThreads].compare_exchange_strong(expected, true)) {
        return id % kMaxNumThreads;
      }
    }
    // Already have 64 active threads.
    throw std::runtime_error{ "Too many threads!" };
  }

  /// The current thread's page_index.
  static thread_local ThreadId id_;

  /// Next thread index to consider.
  static std::atomic<uint32_t> next_index_;
  /// Which thread IDs have already been taken.
  static std::atomic<bool> id_used_[kMaxNumThreads];
```

注意这里id_used只有kMaxNumThreads大小，没用上预留的2，

注意id_used_的遍历方式，，这个endkMaxNumThreads*2，是一个经典的ring-buffer的循环遍历，比如从最后开始遍历，通过这个end和mod能遍历回来

回到Drain

这里通过ComputeNewSafeToReclaimEpoch来更新epoch



## CPR concurrent prefix recovery

> 这里在一个记录中保存两个数据版本，一个stable和一个live。另外有一个整数来保存当前的版本。一个稳定的状态下面，数据处于一个版本 v。一个CPR commit操作会将这个版本v变为v+1。算法分为几个步骤执行：prepare, in-progress and  wait-flush。为了支持算法的运行，这里维护两个全局的变量  Global.phase和Global.version，分别表示数据库当前的状态和版本。每个线程会拷贝这些信息一个线程局部的版本，只会在epoch synchronization更新线程局部的信息，减少同步的开销

四个状态

REST Commit在数据处于rest  phase状态的时候被请求。设这个时候数据的版本为v。这个阶段由Commit函数触发。这个函数中更新数据库的状态为prepare，并添加一个PrepareToInProg。这个tigger会在所有的线程进入prepare状态后触发。每个线程也会更新本地的保存的信息。之后进入prepare阶段

PREPARE 准备版本推进 这里如果遇到了大于目前版本V的数据版本，这个事务的执行abort。这个线程会更新线程本地的信息

IN-PROGRESS 执行版本推进 PrepareToInProg函数会在所有的线程进入prepare状态之后被触发。它会更新系统的状态为in-progress，然后添加另外的一个trigger，刷新本地的信息。一个In-Progress状态的线程在数据版本为v+1的状态下面执行事务。这个操作的时候，如果一个线程遇到去读写记录集合内，且版本小于v+1的，它会将这些记录的版本信息修改为v+1。这么处理的原因是为了其它线程防止读取到这些还没有提交的数据。为了相互操作的不Blocking。这里会将记录live的数据拷贝到stable部分中。  

WAIT-FLUSH 等待版本下盘 InProgToWaitFlush操作。这个操作会首先设置全局状态信息为wait-flush。如果对于版本信息为v+1的记录，收集起stable版本，否则收集live版本。这个时候进来的事务会按照在in-progress阶段中处理的方式一样处理，所有的记录被收集且持久化之后，更新状态为rest，并更新全局的版本信息为v+1

流程图

<img src="https://wanghenshui.github.io/assets/faster-cpr.png" alt=""  width="100%">



这是论文描述的状态，实际上的状态已经复杂成这样了, 新的状态流转后面再整理

```c++
/// Phases, used internally by FASTER to keep track of how far along FASTER has gotten during
/// checkpoint, gc, and grow actions.
enum class Phase : uint8_t {
  /// Checkpoint phases.
  PREP_INDEX_CHKPT,
  INDEX_CHKPT,
  PREPARE,
  IN_PROGRESS,
  WAIT_PENDING,
  WAIT_FLUSH,
  REST,
  PERSISTENCE_CALLBACK,
  /// Garbage-collection phases.
  /// - The log's begin-address has been shifted; finish all outstanding I/Os before trying to
  ///   truncate the log.
  GC_IO_PENDING,
  /// - The log has been truncated, but threads are still cleaning the hash table.
  GC_IN_PROGRESS,
  /// Grow-index phases.
  /// - Each thread waits for all other threads to complete outstanding (synchronous) operations
  ///   against the hash table.
  GROW_PREPARE,
  /// - Each thread copies a chunk of the old hash table into the new hash table.
  GROW_IN_PROGRESS,
  INVALID
};
```



进入checkpoint状态会加锁

CheckpointLocks是一个AtomicCheckpointLock数组，初始化根据多少个hash创建多少个锁

AtomicCheckpointLock就是封装CheckpointLock，CheckpointLock比较常规

```c++
  union {
      struct {
        uint32_t old_lock_count_;
        uint32_t new_lock_count_;
      };
      uint64_t control_;
    };
```

一个是旧的版本锁，一个是新的版本锁

同时只能锁一个，对应count++，解锁对应count--，当且仅当另一个锁没有上锁的时候才能有动作

```c++
  /// Try to lock the old version of a record.
  inline bool try_lock_old() {
    CheckpointLock expected{ control_.load() };
    while(expected.new_lock_count_ == 0) {
      CheckpointLock desired{ expected.old_lock_count_ + 1, 0 };
      if(control_.compare_exchange_strong(expected.control_, desired.control_)) {
        return true;
      }
    }
    return false;
  }
  inline void unlock_old() {
    control_ -= CheckpointLock{ 1, 0 } .control_;
  }
```



## 文件处理

FileSystemDisk

核心在 FileSystemFile<handler_t>, FileSystemSegmentedFile<handler_t, S>;

这里的handler_t是

```c++
#ifdef _WIN32
typedef FASTER::environment::ThreadPoolIoHandler handler_t;
#else
typedef FASTER::environment::QueueIoHandler handler_t;
#endif
```

真正的文件操作封装在这里，linux使用aio写的



对于文件分段管理，具体有FileSystemSegmentBundle和FileSystemSegmentedFile



## hashtable

### InternalHashTable

就是个bucket数组，还有一些记录信息

```c++
  uint64_t size_;
  HashBucket* buckets_;

  /// State for ongoing checkpoint/recovery.
  disk_t* disk_;
  file_t file_;
```



### hashbucket

用到了和address相同的对齐技巧

核心是bucket，bucket也是和cacheline对齐的

```c++
struct alignas(Constants::kCacheLineBytes) HashBucket {
  /// Number of entries per bucket (excluding overflow entry).
  static constexpr uint32_t kNumEntries = 7;
  /// The entries.
  AtomicHashBucketEntry entries[kNumEntries];
  /// Overflow entry points to next overflow bucket, if any.
  AtomicHashBucketOverflowEntry overflow_entry;
};
static_assert(sizeof(HashBucket) == Constants::kCacheLineBytes,
              "sizeof(HashBucket) != Constants::kCacheLineBytes");
```

HashBucketOverflowEntry只有个address_

```c++
  union {
      struct {
        uint64_t address_ : 48; // corresponds to logical address
        uint64_t unused_ : 16;
      };
      uint64_t control_;
    };
```



HashBucketEntry长这样

```c++

  union {
      struct {
        uint64_t address_ : 48; // corresponds to logical address一般指针只用到48位
        uint64_t tag_ : 14;  //用来保存hash，类似cuckoohash，防撞
        uint64_t reserved_ : 1;
        uint64_t tentative_ : 1;  //如果是1，说明在外面
      };
      uint64_t control_;
    };
```



注意一个hashbucket有七个HashBucketEntry，这七个是相同的hash，如何判断在哪个bucketEntry？用tag

TODO: tag的生成逻辑? 目前来看就是hash.tag

如果有tentative标记，说明重复，正在写，重新分配通过BucketOverflowEntry指向外面的entry

### MallocFixedPageSize

结构是这样的

```c++
/// Alignment at which each page is allocated.
  uint64_t alignment_;
  /// Array of all of the pages we've allocated.
  std::atomic<FixedPageArray<T>*> page_array_;
  /// How many elements we've allocated.
  AtomicFixedPageAddress count_;

  LightEpoch* epoch_;

  /// State for ongoing checkpoint/recovery.
  disk_t* disk_;
  file_t file_;
  std::atomic<uint64_t> pending_checkpoint_writes_;
  std::atomic<uint64_t> pending_recover_reads_;
  std::atomic<bool> checkpoint_pending_;
  std::atomic<bool> checkpoint_failed_;
  std::atomic<bool> recover_pending_;
  std::atomic<bool> recover_failed_;

  FreeList free_list_[Thread::kMaxNumThreads];
```

用disk.log().asignement初始化

TODO: 一个fasterkv 使用的大小？

## Hlog PersistentMemoryMalloc

hlog构成

```c++
  log_file_t* file;
  // Read buffer pool
  NativeSectorAlignedBufferPool read_buffer_pool;
  NativeSectorAlignedBufferPool io_buffer_pool;

  /// Every address < ReadOnlyAddress is read-only.
  AtomicAddress read_only_address;
  /// The minimum ReadOnlyAddress that every thread has seen.
  AtomicAddress safe_read_only_address;

  /// The circular buffer can drop any page < HeadAddress.page()--must read those pages from disk.
  AtomicAddress head_address;
  /// The minimum HeadPage that every thread has seen.
  AtomicAddress safe_head_address;

  AtomicAddress flushed_until_address;

  /// The address of the true head of the log--everything before this address has been truncated
  /// by garbage collection.
  AtomicAddress begin_address;

  uint32_t buffer_size_;
  bool pre_allocate_log_;

  /// -- the latest N pages should be mutable.
  uint32_t num_mutable_pages_;

  // Circular buffer definition
  uint8_t** pages_;

  // Array that indicates the status of each buffer page
  FullPageStatus* page_status_;

  // Global address of the current tail (next element to be allocated from the circular buffer)
  AtomicPageOffset tail_page_offset_;
```

重点关注这几个address

​    buffer_size_ = static_cast<uint32_t>(log_size / kPageSize); PageSize是32M log_size指定不能大于UINT32_MAX 也就是128PB，也不能小于32M

num_mutable_pages_要大于2 kNumHeadPages是4，在hlog开头

每一个page都是有FullPageStatus来描述，这里有个状态机驱动FlushCloseStatus，默认FlushStatus::Flushed, CloseStatus::Open

```c
/// Pack flush- and close-status into a single 16-bit value.
/// State transitions are:
/// { Flushed, Closed } (default state)
/// --> { InProgress, Open } (when issuing the flush to disk)
/// --> either { . , Closed} (when moving the head address forward)
///     or     { Flushed, . } (when the flush completes).
```



- HandleSpecialPhases/SplitHashTableBuckets
  - GlobalMoveToNextState
    - AsyncFlushPagesToFile



- NewPage
  - PageAlignedShiftReadOnlyAddress
    - MonotonicUpdate
    - BumpCurrentEpoch 
      - OnPagesMarkedReadOnly
        - AsyncFlushPages



### pageoffset

```c++
  /// Use 41 bits for offset, which gives us approximately 2 PB of overflow space, for
  /// Reserve().
  union {
      struct {
        uint64_t offset_ : 64 - Address::kPageBits; //41
        uint64_t page_ : Address::kPageBits; //23
      };
      uint64_t control_;
    };
//
  inline PageOffset Reserve(uint32_t num_slots) {
    assert(num_slots <= Address::kMaxOffset);
    PageOffset offset{ 0, num_slots };
    return PageOffset{ control_.fetch_add(offset.control()) };
  }
```

根据record大小算page，page的下一页用来具体的写



TODO: hlog占用的大小？

## Record

record对应recordinfo，以及真正的kv 注意，kv封装在一起

recordinfo结构

```c++
  union {
      struct {
        uint64_t previous_address_ : 48;
        uint64_t checkpoint_version : 13;
        uint64_t invalid : 1;
        uint64_t tombstone : 1;
        uint64_t final_bit : 1;
      };

      uint64_t control_;
    };
```

所有的字段排布都是pad_alignment的，保证8的整数倍

这里要求size和alignment都是2的幂

```c++
constexpr inline size_t pad_alignment(size_t size, size_t alignment) {
  size_t max_padding = alignment - 1;
  return (size + max_padding) & ~max_padding;
}
pad_alignment(sizeof(int64_t), alignof(std::string)); //8
```

这里引入一下对齐要求

> 每个[对象类型](https://zh.cppreference.com/w/cpp/language/type)都具有被称为*对齐要求（alignment requirement）*的性质，它是一个整数（类型为 [std::size_t](https://zh.cppreference.com/w/cpp/types/size_t)，总是 2 的幂），表示这个类型的不同对象所能分配放置的连续相邻地址之间的字节数。
>
> | 可以用 [`alignof`](https://zh.cppreference.com/w/cpp/language/alignof) 或 [std::alignment_of](https://zh.cppreference.com/w/cpp/types/alignment_of) 来查询类型的对齐要求。可以使用指针对齐函数 [std::align](https://zh.cppreference.com/w/cpp/memory/align) 来获取某个缓冲区中经过适当对齐的指针，还可以使用 [std::aligned_storage](https://zh.cppreference.com/w/cpp/types/aligned_storage) 来获取经过适当对齐的存储区。 | (C++11 起)   |
> | ------------------------------------------------------------ | ------------ |
> | 每个对象类型在该类型的所有对象上强制该类型的对齐要求；可以使用 [`alignas`](https://zh.cppreference.com/w/cpp/language/alignas) 来要求更严格的对齐（更大的对齐要求） | (C++11 起)。 |
>
> 为了使[类](https://zh.cppreference.com/w/cpp/language/class)中的所有非静态成员都符合对齐要求，会在一些成员后面插入一些*填充*。



用上alignof就要求保证最大对齐。这里也是cache 友好的一种手段



回到record record的size保证是8的整数倍, 在内存中

在磁盘中，省掉了value的padding

```c++
  /// Size of a record to be created, in memory. (Includes padding, if any, after the value, so
  /// that the next record stored in the log is properly aligned.)
  static inline constexpr uint32_t size(uint32_t key_size, uint32_t value_size) {
    return static_cast<uint32_t>(
             // --plus Value size, all padded to Header alignment.
             pad_alignment(value_size +
                           // --plus Key size, all padded to Value alignment.
                           pad_alignment(key_size +
                                         // Header, padded to Key alignment.
                                         pad_alignment(sizeof(RecordInfo), alignof(key_t)),
                                         alignof(value_t)),
                           alignof(RecordInfo)));

  /// Size of a record, on disk. (Excludes padding, if any, after the value.)
  inline constexpr uint32_t disk_size() const {
    return static_cast<uint32_t>(value().size() +
                                 pad_alignment(key().size() +
                                     // Header, padded to Key alignment.
                                     pad_alignment(sizeof(RecordInfo), alignof(key_t)),
                                     alignof(value_t)));
```



## Context

PersistentExecContext checkpoint信息

ExecutionContext 增加了phase状态

还有这几个成员

```c++
  Phase phase;

  /// Retry request contexts are stored inside the deque.
  std::deque<IAsyncContext*> retry_requests;
  /// Assign a unique ID to every I/O request.
  uint64_t io_id;
  /// For each pending I/O, maps io_id to the hash of the key being retrieved.
  std::unordered_map<uint64_t, KeyHash> pending_ios;

  /// The I/O completion thread hands the PendingContext back to the thread that issued the
  /// request.
  concurrent_queue<AsyncIOContext*> io_responses;
```

threadContext是ExecutionContext的封装，每个thread有两个executioncontext

```c++
class alignas(Constants::kCacheLineBytes) ThreadContext {
 public:
  ThreadContext()
    : contexts_{}
    , cur_{ 0 } {
  }

  inline const ExecutionContext& cur() const {
    return contexts_[cur_];
  }
  inline ExecutionContext& cur() {
    return contexts_[cur_];
  }

  inline const ExecutionContext& prev() const {
    return contexts_[(cur_ + 1) % 2];
  }
  inline ExecutionContext& prev() {
    return contexts_[(cur_ + 1) % 2];
  }

  inline void swap() {
    cur_ = (cur_ + 1) % 2;
  }

 private:
  ExecutionContext contexts_[2];
  uint8_t cur_;
};
```

CallbackContext

IAsyncContext 封装CURD的context信息，特殊的context需要特别的方法，塞value之类的

PendingContext<key_t> 把IAsyncContext和callback包装起来

pendingcontext信息

```c++
  /// Caller context.
  IAsyncContext* caller_context;
  /// Caller callback.
  AsyncCallback caller_callback;
  /// Checkpoint version.
  uint32_t version;
  /// Checkpoint phase.
  Phase phase;
  /// Type of operation (Read, Upsert, RMW, etc.).
  OperationType type;
  /// Result of operation.
  Status result;
  /// Address of the record being read or modified.
  Address address;
  /// Hash table entry that (indirectly) leads to the record being read or modified.
  HashBucketEntry entry;
```

状态机流转都是靠pendingcontext



## AIO aio相关的使用

这里设计了一个context

塞了自己的context

```c++
  struct IoCallbackContext {
    IoCallbackContext(FileOperationType operation, int fd, size_t offset, uint32_t length,
                      uint8_t* buffer, core::IAsyncContext* context_, core::AsyncIOCallback callback_)
      : caller_context{ context_ }
      , callback{ callback_ } {
      if(FileOperationType::Read == operation) {
        ::io_prep_pread(&this->parent_iocb, fd, buffer, length, offset);
      } else {
        ::io_prep_pwrite(&this->parent_iocb, fd, buffer, length, offset);
      }
      ::io_set_callback(&this->parent_iocb, IoCompletionCallback);
    }

    // WARNING: "parent_iocb" must be the first field in AioCallbackContext. This class is a C-style
    // subclass of "struct iocb".

    /// The iocb structure for Linux AIO.
    struct iocb parent_iocb;

    /// Caller callback context.
    core::IAsyncContext* caller_context;

    /// The caller's asynchronous callback function
    core::AsyncIOCallback callback;
  };
```



io_submit塞这个context，io_getevent拿数据

## 读

- Read

  - InternalRead，三种状态，内存中，磁盘中，还是未找到

    - 判断当前所处的cpr状态 如果不是REST，是其他状态，需要做一些标记动作HeavyEnter
    - 根据context带来的key的hash来FindEntry
      - 判定在那个version对应的hashtable中
        - Action::GrowIndex控制version
      - 如果internalHashTable中的HashBucketEntry不满足条件，那就找HashBucketEntry中对应的外部表`bucket = &overflow_buckets_allocator_[version].Get(entry.address());`如果没位置了，继续放到外部
    - 判定Entry所在的address满足条件，拿到address，从hlog找到对应的record和查找的key进行比对
      - 如果record->key不等于context带回来的key，走碰撞查询 TraceBackForKeyMatchCtxt, LRU的

  - HandleOperationStatus 读磁盘/重试

    - IssueAsyncIoRequest

      - AsyncGetFromDisk, 带上AsyncGetFromDiskCallback

        - Epoch protect状态处理 

          - disk.TryComplete(); 
            - 进行io动作 io_getevents
              - AsyncGetFromDiskCallback
          - std::this_thread::yield();
          -  epoch_.ProtectAndDrain();

        - hlog->AsyncGetFromDisk

          - file->ReadAsync AIO, FileSystemSegmentedFile

            - OpenSegment, load或者保存对应的段

            - files->file(segment).ReadAsync(source % kSegmentSize, dest, length, callback, context); FileSystemSegmentBundle<handler_t>

              - FileSystemFile->ReadAsync

                - QueueFile::Read

                  - IoCallbackContext
                    - io_prep_pread
                    - io_set_callback 到这层 callback设置好
                  - io_submit 带着IoCallbackContext一起提交

                  

  ```c++
    case OperationStatus::RECORD_ON_DISK:
      if(thread_ctx().phase == Phase::PREPARE) {
        assert(pending_context.type == OperationType::Read ||
               pending_context.type == OperationType::RMW);
        // Can I be marking an operation again and again?
        if(!checkpoint_locks_.get_lock(pending_context.get_key_hash()).try_lock_old()) {
          return PivotAndRetry(ctx, pending_context, async);
        }
      }
      return IssueAsyncIoRequest(ctx, pending_context, async);
  ```



## 读-> 改->写

- Rmw
  - InternalRmw



## 写

- Upsert

  - InternalUpsert

    - FindOrCreateEntry，语义:如果是创建的，地址是Address::kInvalidAddress
      - FindTentativeEntry 找满足条件的找不到用free的，如果没有free的，用overflow_entry
        - 语义: 返回bucketEntry，并且能判断是free的还是已经存在的
        - 如果overflow_entry没用，就分配一个`overflow_buckets_allocator_[version].Allocate();` address，根据这个address创建overflow_entry
          - 进行并发修改overflow_entry
            - 如果成功就把allocate好的address对应的bucket返回
            - 失败，回退，回收对应的address
        - 如果overflow_entry已经分配，那就直接返回对应的bucket
      - 根据FindTentativeEntry判定，如果是free的，写tag, 标记tentative，并发写，写成功就清掉tentative，写失败
        - HasConflictingEntry检查是否有相同tag，有，说明冲突，继续循环写
    - 判定Entry所在的address满足条件，拿到address，
      - 如果大于head_address, 根据地址从hlog找到对应的record
        - 如果record->key不等于context带回来的key，走碰撞查询 TraceBackForKeyMatchCtxt, LRU的
    - `thread_ctx().phase == Phase::REST && address >= read_only_address` 开始正常写入，从hlog抠出record
      - `pending_context.PutAtomic(record)`
      - 如果record不存在，已经被回收tombstone，需要走RCU更新 goto create_record
    - CPR状态机处理
      - PREPARE阶段，主要是处理旧的版本 CPR_SHIFT_DETECTED 条件 
        - 锁旧锁失败，说明当前肯定有更旧的，不然我们是最后一个旧的，就能锁上
        - `latest_record_version > thread_ctx().version` 我们看到了比我们版本还要大的，需要调整version
      - IN_PROGRESS阶段，锁新锁，失败重试，成功进入create_record流程
      - WAIT_PENDING阶段，等待旧锁释放，进入create_record
      - WAIT_FLUSH阶段，直接create_record
    - Mutable region， PutAtomic
    - create_record

    ```c++
      uint32_t record_size = record_t::size(pending_context.key_size(), pending_context.value_size());
      Address new_address = BlockAllocate(record_size);
      record_t* record = reinterpret_cast<record_t*>(hlog.Get(new_address));
      new(record) record_t{
        RecordInfo{
          static_cast<uint16_t>(thread_ctx().version), true, false, false,
          expected_entry.address() }
      };
      pending_context.write_deep_key_at(const_cast<key_t*>(&record->key()));
      pending_context.Put(record);
    
      HashBucketEntry updated_entry{ new_address, hash.tag(), false };
      if(atomic_entry->compare_exchange_strong(expected_entry, updated_entry)) {
        // Installed the new record in the hash table.
        return OperationStatus::SUCCESS;
      } else {
        // Try again.
        record->header.invalid = true;
        return InternalUpsert(pending_context);
      }
    ```

  

  
```c++
  template <class K, class V, class D>
  inline Address FasterKv<K, V, D>::BlockAllocate(uint32_t record_size) {
    uint32_t page;
    Address retval = hlog.Allocate(record_size, page);
    while(retval < hlog.read_only_address.load()) {
      Refresh();
      // Don't overrun the hlog's tail offset.
      bool page_closed = (retval == Address::kInvalidAddress);
      while(page_closed) {
        page_closed = !hlog.NewPage(page);
        Refresh();
      }
      retval = hlog.Allocate(record_size, page);
    }
    return retval;
  }
  
  
  
  template <class D>
  inline Address PersistentMemoryMalloc<D>::Allocate(uint32_t num_slots, uint32_t& closed_page) {
    closed_page = UINT32_MAX;
    PageOffset page_offset = tail_page_offset_.Reserve(num_slots);
  
    if(page_offset.offset() + num_slots > kPageSize) {
      // The current page is full. The caller should Refresh() the epoch and wait until
      // NewPage() is successful before trying to Allocate() again.
      closed_page = page_offset.page();
      return Address::kInvalidAddress;
    } else {
      assert(Page(page_offset.page()));
      return static_cast<Address>(page_offset);
    }
  }
  ```
  
  
  
  - 操作失败的HandleOperationStatus 状态机
  
    - CPR_SHIFT_DETECTED PivotAndRetry,推进版本号
      - Refresh
        - epoch_.ProtectAndDrain
        - HandleSpecialPhases
          - Action phase双层状态机 所有东西都混在一起了。难受



## 参考信息

- https://github.com/microsoft/FASTER
- https://zhuanlan.zhihu.com/p/111130238
- https://www.zhihu.com/question/291185867
- https://nan01ab.github.io/2019/05/FASTER.html
- https://microsoft.github.io/FASTER/docs/td-slides-videos/
  - https://www.youtube.com/watch?v=68YBpitMrMI 咖喱味太重了，基本听不明白
- https://microsoft.github.io/FASTER/docs/td-research-papers/
- https://zh.cppreference.com/w/c/memory/aligned_alloc

> void *aligned_alloc( [size_t](http://zh.cppreference.com/w/c/types/size_t) alignment, [size_t](http://zh.cppreference.com/w/c/types/size_t) size );
>
> 分配 `size` 字节未初始化的存储空间，按照 `alignment` 指定对齐。 `size` 参数必须是 `alignment` 的整数倍。

- https://github.com/microsoft/FishStore 师出同门 
  - https://badrish.net/papers/fishstore-sigmod19.pdf
- 给faster加上io uring https://github.com/microsoft/FASTER/pull/387/files



---

看到这里或许你有建议或者疑问或者指出我的错误，请留言评论或者邮件mailto:wanghenshui@qq.com, 多谢! 
<details>
<summary>觉得写的不错可以点开扫码赞助几毛</summary>
<img src="https://wanghenshui.github.io/assets/wepay.png" alt="微信转账">
</details>