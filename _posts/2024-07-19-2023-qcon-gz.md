---
layout: post
title: qcon2023广州PPT速览
categories: [database]
tags: [byconity, antkv, rocksdb, clickhouse]
---
ppt在这里 https://www.modb.pro/topic/640977

只有两个感兴趣

https://wanghenshui.github.io/pdf/byconity.pdf


https://wanghenshui.github.io/pdf/antkv.pdf

<!-- more -->

### AntKV: 蚂蚁实时计算 KV 分离5x性能提升实践

WiscKey的rocksdb改造工作

AntKV 核心功能
- KV分离
  - 元数据管理
- 空间回收
  - GC
  - TTL
- 数据版本
  - Checkpoint
  - Ingest Value Log Files
- 特性支持
  - 异步恢复Checkpoint
  - Table API
- 性能优化
  - **Scan 优化**
  - 流控优化
  - **Learned Index**


**Scan优化**

kv分离现状
- value 是vlog追加模式
- 访问value多一跳
- 导致scan局部性差

优化策略，并发prefetch
- 根据用户访问 Pattern 或者 Range Hint 发起异步预取
- 发挥 NVMe SSD 能力并行预取
- 利用 Block Cache 实现数据同步


<img src="https://wanghenshui.github.io/assets/antkv1.png" alt="" width="60%">

新的问题
- 中等大小（如256B）Value 情况下，Scan 仍然比 RocksDB 差很多


原因
- Block 中数据不连续，磁盘带宽即便打满，大多内容都是无效数据

优化策略 Diffkv ATC 21: Differentiated Key-Value Storage Management for Balanced I/O Performance


核心思路
- 对于中等大小的 KV pairs，对 Value Log Files也进行分层处理，增强局部连续性
  - Level N-2 及以下的层级不做重写
  - Level N-1 及以上的层级在 Compaction 时重写Value Log Files

<img src="https://wanghenshui.github.io/assets/antkv2.png" alt="" width="60%">  

- 针对 Scan 优化的重写：
  - Compaction 过程中，对本轮参与的 Value Log Files 进行重叠记数
  -  当发现某文件重叠记数超过阈值，则标记相关文件后续进行重写


<img src="https://wanghenshui.github.io/assets/antkv3.png" alt="" width="60%">

收益 写入降低30% 但scan提升巨大

这种还是要考虑业务来使用，但是这个工作是很亮眼的

**借助 Learned Index 优化查询**

Learned Index主要是要设计构建算法，这里需要展开一下


<img src="https://wanghenshui.github.io/assets/antkv-li1.png" alt="" width="60%">


<img src="https://wanghenshui.github.io/assets/antkv-li2.png" alt="" width="60%">

因为实际 SST 保存的 key 为 string 类型，非 integer，因此需要进行转换
- 要求
  - 唯一性：不同的 key，转换出来的 key_digest 不能相同
  - 保序性：如果 key1 < key2，那么转换后的 key_digest_1 < key_digest_2
- 问题
  - 字符串长度是随机的，并且可能很长


<img src="https://wanghenshui.github.io/assets/antkv-li3.png" alt="" width="60%">


Learned Index非常小，读效率非常高

Learned Index: 生成过程

- 在构建新的SST过程中，会缓存待写入的所有KV数据，在Finish时进行建模并持久化相关参数。
  - 不会在L0构建Learned Index
  - 不会对大小在阈值以下的SST进行构建
  -  当不满足构建条件时，退化为默认的Binary Index


### ByConity：基于云原⽣架构的开源实时数仓系

clickhouse痛点
- Shared Nothing架构
  - 运维困难：扩缩容、读写分离、资源隔离困难
  - 资源浪费：存储和计算⽆法独⽴扩容、弹性伸缩
- 事务⽀持缺失
  - 不满⾜对数据⼀致性要求⾼的场景
  - 提⾼了使⽤和运维成本
  - 复杂查询性能差（如多表Join)

架构 

设计考虑

- 需要统⼀的元信息管理系统
- 分布式⽂件系统⼤多数存在元信息管理压⼒问题
- 分布式统⼀存储系统⼤多不⽀持rewrite，⼀些对象存储系统甚⾄不⽀持append
- 分布式对象存储系统⼤多move代价都⽐较⾼
- io latency通常情况对⽐本地⽂件系统下都存在增加的情况

数据缓存

- ⼀致性hash分配parts
- 热数据worker节点⾃动缓存
- 改进bucket-lru算法
- 避免数据reshuffling

ByConity事务
- 隐式（开源）和显示事务（待开源）
- Read Committed 隔离级别，写不阻塞读
- 两阶段提交实现，⽀持海量数据的原⼦写⼊
- 具备灵活可控的并发控制的功能


中⼼授时服务TSO(TimeStamp Oracle)
- Timestamp ordering
- 创建事务：为事务分配开始时间t_s
- 提交事务：为事务分配提交时间t_c
- 可⻅性判断：对t_s为TS的事务，能读到所有已提交且t_c < TS的事务数据

说的东西还是非常多的，直接看pdf比我复述直观


https://wanghenshui.github.io/pdf/byconity.pdf